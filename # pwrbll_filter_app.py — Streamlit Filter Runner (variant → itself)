
from __future__ import annotations

import hashlib
import io
import re
from collections import Counter
from dataclasses import dataclass
from typing import Any, Dict, List, Tuple

import pandas as pd
import streamlit as st

# =======================
# Runtime / safety config
# =======================
REVERSE_THRESHOLD_DEFAULT = 0.75
KEEPER_THRESHOLD_DEFAULT = 0.25
MAX_DETAILED_ROWS = 200_000

# =======================
# UI helpers
# =======================
def download_pair(df: pd.DataFrame, base: str) -> None:
    if df is None or df.empty:
        st.caption(f"({base}: no rows)")
        return
    csv_bytes = df.to_csv(index=False).encode("utf-8")
    txt_bytes = df.to_csv(index=False, sep="\t").encode("utf-8")
    c1, c2 = st.columns(2)
    with c1:
        st.download_button(f"‚¨áÔ∏è Download {base}.csv", csv_bytes, f"{base}.csv", "text/csv", use_container_width=True)
    with c2:
        st.download_button(f"‚¨áÔ∏è Download {base}.txt", txt_bytes, f"{base}.txt", "text/plain", use_container_width=True)

def md5_bytes(b: bytes) -> str:
    return hashlib.md5(b).hexdigest()

# =======================
# Robust draw loader
# =======================
def load_draws_from_text(text: str, reverse_input: bool = False) -> List[List[int]]:
    """
    Lines like:
      Sat, Aug 30, 2025  03-18-22-27-33, Powerball: 17
    ‚Üí [[3,18,22,27,33], ...]  (Powerball ignored by design)
    """
    draws: List[List[int]] = []
    pat = re.compile(r'(?<!\d)(\d{1,2})\D+(\d{1,2})\D+(\d{1,2})\D+(\d{1,2})\D+(\d{1,2})(?!\d)')
    for line in text.splitlines():
        m = pat.search(line)
        if m:
            draws.append([int(g) for g in m.groups()])
    if reverse_input:
        draws.reverse()
    return draws

# =======================
# Variants (13) + helpers
# =======================
def five_positions(draw: List[int]) -> List[int]: return list(draw)
def ones_digits_list(draw: List[int]) -> List[int]: return [n % 10 for n in draw]
def tens_digits_list(draw: List[int]) -> List[int]: return [n // 10 for n in draw]
def pos_digit_sums(draw: List[int]) -> List[int]: return [(n // 10) + (n % 10) for n in draw]
def full_sum(draw: List[int]) -> int: return sum(draw)

def variant_value(draw: List[int], variant: str) -> Any:
    if variant == "full": return full_sum(draw)
    if variant == "ones": return sum(ones_digits_list(draw))
    if variant == "tens": return sum(tens_digits_list(draw))
    if variant.startswith("possum"): return pos_digit_sums(draw)[int(variant[-1]) - 1]
    if variant.startswith("pos"):    return five_positions(draw)[int(variant[-1]) - 1]
    raise ValueError(f"Unknown variant {variant}")

def all_variants() -> List[str]:
    return ["full","ones","tens"] + [f"pos{i}" for i in range(1,6)] + [f"possum{i}" for i in range(1,6)]

# =======================
# Hot / Cold / Due (variant-aware)
# =======================
def atoms_for_hotcold(window_draws: List[List[int]], variant: str) -> List[int]:
    a: List[int] = []
    if variant == "ones":
        for d in window_draws: a.extend(ones_digits_list(d))
    elif variant == "tens":
        for d in window_draws: a.extend(tens_digits_list(d))
    elif variant.startswith("possum"):
        j = int(variant[-1]) - 1
        for d in window_draws: a.append(pos_digit_sums(d)[j])
    elif variant.startswith("pos"):
        j = int(variant[-1]) - 1
        for d in window_draws:
            n = five_positions(d)[j]
            a.extend([n//10, n%10])
    else:  # full
        for d in window_draws:
            for n in d: a.extend([n//10, n%10])
    return a

def compute_hot_cold_due(history: List[List[int]], idx: int, variant: str,
                         hc_win: int, due_win: int):
    start = max(0, idx - hc_win)
    window = history[start:idx]
    cnt = Counter(atoms_for_hotcold(window, variant))
    if cnt:
        maxf, minf = max(cnt.values()), min(cnt.values())
        hot  = sorted([k for k,c in cnt.items() if c == maxf])
        cold = sorted([k for k,c in cnt.items() if c == minf])
    else:
        hot, cold = [], []
    recent = history[max(0, idx - due_win):idx]
    rdig: List[int] = []
    for d in recent:
        for n in d: rdig.extend([n//10, n%10])
    due = sorted(list(set(range(10)) - set(rdig)))
    return hot, cold, due

# =======================
# Helpers for expressions
# =======================
def spread_value(v) -> int:
    return (max(v) - min(v)) if isinstance(v,(list,tuple)) and len(v)==5 else 0

def unique_digits_count(v) -> int:
    digits = []
    if isinstance(v,(list,tuple)):
        for n in v: digits.extend([n//10,n%10])
    else:
        for ch in str(int(v)): digits.append(int(ch))
    return len(set(digits))

def is_triple_draw(v) -> bool:
    digits = []
    if isinstance(v,(list,tuple)):
        for n in v: digits.extend([n//10,n%10])
    else:
        for ch in str(int(v)): digits.append(int(ch))
    return any(c>=3 for c in Counter(digits).values())

def shared_digits_count(seed_draw, win_draw) -> int:
    s,w=[],[]
    for n in seed_draw: s.extend([n//10,n%10])
    for n in win_draw:  w.extend([n//10,n%10])
    return len(set(s)&set(w))

ALLOWED_GLOBALS = {
    "spread": spread_value,
    "unique_digits": unique_digits_count,
    "is_triple": is_triple_draw,
    "shared_digits": shared_digits_count,
    "min": min, "max": max, "abs": abs, "sum": sum, "len": len,
    "set": set, "any": any, "all": all, "sorted": sorted, "range": range,
    "Counter": Counter,
}

def layman_explanation(expr: str) -> str:
    if not expr: return "Unparseable / constant"
    repl = {"seed":"seed value","winner":"winner value","==":"equals","<=":"is ‚â§",">=":"is ‚â•","<":"is <",">":"is >", " and ":" AND "," or ":" OR "}
    text = expr
    for k,v in repl.items(): text = text.replace(k,v)
    return f"Eliminate if {text}"

# =======================
# Legacy normalization
# =======================
LEGACY_MAP = [
    (r"\bcombo_sum\b","winner"), (r"\bcombo_total\b","winner"), (r"\bcombo\b","winner"),
    (r"\bcombo_structure\b","winner_structure"),
    (r"\bseed_sum\b","seed"), (r"\bseed_total\b","seed"),
    (r"\bones_total\b","winner"), (r"\btens_total\b","winner"),
    (r"\bfull_combo\b","winner"),
    (r"\b&\b"," and "), (r"\b\|\b"," or "),
    (r"‚Äú|‚Äù|‚Äò|‚Äô","\""), (r"‚â§","<="),(r"‚â•",">="),(r"‚â†","!="),(r"‚Äì","-"),
]
BOOLEAN_LITERALS = {"true","false","1","0","yes","no"}

def is_boolean_literal(s: str) -> bool:
    return s.strip().lower() in BOOLEAN_LITERALS

def normalize_expression(expr: str) -> str:
    if not isinstance(expr,str): return ""
    e = expr.strip()
    if not e: return ""
    e = e.strip("\"'")
    low = e.lower()
    if "see prior" in low or "see conversation" in low: return ""
    for pat,repl in LEGACY_MAP: e = re.sub(pat, repl, e, flags=re.IGNORECASE)
    e = re.sub(r"\bAND\b","and",e); e = re.sub(r"\bOR\b","or",e)
    if is_boolean_literal(e): return ""   # guard against constants
    return e

def load_filters_any(text: str) -> List[Tuple[str,str]]:
    lines = text.splitlines()
    if not lines: return []
    hdr = lines[0].lower()
    header_like = ("," in lines[0]) and (("expression" in hdr) or ("applicable" in hdr) or ("expr" in hdr))
    if header_like:
        df = pd.read_csv(io.StringIO(text))
        expr_col = None
        for c in df.columns:
            if c.lower() in ("expression","expr"):
                expr_col = c; break
        if expr_col is None:
            for c in df.columns:
                if "applicable" in c.lower():
                    vals = set(str(x).strip().lower() for x in df[c].dropna().unique().tolist())
                    if not vals or vals.issubset(BOOLEAN_LITERALS): continue
                    expr_col = c; break
        if expr_col is None: return []
        id_col = None
        for cand in ("id","filter_id","name"):
            if cand in df.columns: id_col = cand; break
        if id_col is None: id_col = df.columns[0]
        out=[]
        for _,row in df.iterrows():
            fid = str(row[id_col])
            expr_raw = row[expr_col]
            expr = normalize_expression("" if pd.isna(expr_raw) else str(expr_raw))
            if expr: out.append((fid, expr))
        return out
    # simple id,expression
    out=[]
    for raw in lines:
        line = raw.strip()
        if not line or line.startswith("#"): continue
        parts = [p.strip() for p in line.split(",",1)]
        if len(parts)==2:
            fid, expr = parts[0], normalize_expression(parts[1])
            if expr: out.append((fid, expr))
    return out

# =======================
# Context helpers
# =======================
def all_digits(draw: List[int]) -> List[int]:
    d = []
    for n in draw: d.extend([n//10, n%10])
    return d

def build_ctx(seed_draw: List[int], win_draw: List[int], variant: str,
              hot: List[int], cold: List[int], due: List[int]) -> Dict[str, Any]:
    ctx: Dict[str,Any] = {
        "variant_name": variant,

        "seed_draw": seed_draw, "winner_draw": win_draw,
        "seed": variant_value(seed_draw, variant),
        "winner": variant_value(win_draw, variant),

        # digits lists
        "ones_digits": ones_digits_list(win_draw),
        "tens_digits": tens_digits_list(win_draw),
        "seed_ones_digits": ones_digits_list(seed_draw),
        "seed_tens_digits": tens_digits_list(seed_draw),
        "sum_ones": sum(ones_digits_list(win_draw)),
        "sum_tens": sum(tens_digits_list(win_draw)),
        "seed_sum_ones": sum(ones_digits_list(seed_draw)),
        "seed_sum_tens": sum(tens_digits_list(seed_draw)),

        # spreads
        "seed_spread": spread_value(seed_draw),
        "combo_spread": spread_value(win_draw),

        # full / ones / tens totals (aliases)
        "seed_full": variant_value(seed_draw,"full"),
        "winner_full": variant_value(win_draw,"full"),
        "seed_ones_total": variant_value(seed_draw,"ones"),
        "winner_ones_total": variant_value(win_draw,"ones"),
        "seed_tens_total": variant_value(seed_draw,"tens"),
        "winner_tens_total": variant_value(win_draw,"tens"),

        # legacy alias names many filters used:
        "combo_sum": variant_value(win_draw,"full"),
        "combo_total": variant_value(win_draw,"full"),
        "combo_ones_total": variant_value(win_draw,"ones"),
        "combo_tens_total": variant_value(win_draw,"tens"),

        # hot/cold/due
        "hot": hot, "cold": cold, "due": due,
        "hot_digits": hot, "cold_digits": cold, "due_digits": due,
    }

    # positional numbers / tens / ones / digit sums + short aliases
    for j in range(1,6):
        wnum = variant_value(win_draw, f"pos{j}")
        snum = variant_value(seed_draw, f"pos{j}")
        wt, wo = wnum//10, wnum%10
        st, so = snum//10, snum%10
        wds, sds = wt+wo, st+so
        ctx[f"winner_pos{j}_number"]=wnum; ctx[f"seed_pos{j}_number"]=snum
        ctx[f"winner_pos{j}_tens"]=wt;   ctx[f"winner_pos{j}_ones"]=wo
        ctx[f"seed_pos{j}_tens"]=st;     ctx[f"seed_pos{j}_ones"]=so
        ctx[f"winner_pos{j}_digitsum"]=wds; ctx[f"seed_pos{j}_digitsum"]=sds
        # short names used by a lot of batches
        ctx[f"pos{j}_number"]=wnum; ctx[f"pos{j}_tens"]=wt; ctx[f"pos{j}_ones"]=wo; ctx[f"pos{j}_digitsum"]=wds
        # per-position seed digits list
        ctx[f"seed_digits_{j}"] = [st, so]

    ctx.update({
        "pos1_number": ctx["winner_pos1_number"], "pos2_number": ctx["winner_pos2_number"],
        "pos3_number": ctx["winner_pos3_number"], "pos4_number": ctx["winner_pos4_number"],
        "pos5_number": ctx["winner_pos5_number"],
        "pos1_digitsum": ctx["winner_pos1_digitsum"], "pos2_digitsum": ctx["winner_pos2_digitsum"],
        "pos3_digitsum": ctx["winner_pos3_digitsum"], "pos4_digitsum": ctx["winner_pos4_digitsum"],
        "pos5_digitsum": ctx["winner_pos5_digitsum"],
    })

    # mirrors / vtracs / structures
    mirror = {0:5,1:6,2:7,3:8,4:9,5:0,6:1,7:2,8:3,9:4}
    combo_digits = all_digits(win_draw)
    seed_digits  = all_digits(seed_draw)
    combo_vtracs = [d % 5 for d in combo_digits]
    seed_vtracs  = [d % 5 for d in seed_digits]
    winner_structure = unique_digits_count(combo_digits)
    seed_structure   = unique_digits_count(seed_digits)

    ctx.update({
        "mirror": mirror,
        "combo_digits": combo_digits, "seed_digits": seed_digits,
        "combo_vtracs": combo_vtracs, "seed_vtracs": seed_vtracs,
        "winner_structure": winner_structure, "seed_structure": seed_structure,
        "combo_structure": winner_structure,  # legacy alias
    })
    return ctx

# =======================
# Evaluator
# =======================
@dataclass
class EvalSettings:
    hot_cold_window: int
    due_window: int
    keeper_threshold: float
    reverse_threshold: float

@st.cache_data(show_spinner=False)
def evaluate_cached(draws_bytes: bytes, filters_bytes: bytes, reverse_input: bool, settings: EvalSettings):
    draws_text = draws_bytes.decode("utf-8", errors="ignore")
    filters_text = filters_bytes.decode("utf-8", errors="ignore")

    draws = load_draws_from_text(draws_text, reverse_input=reverse_input)
    filters = load_filters_any(filters_text)
    if len(draws) < 2: raise ValueError("Failed to parse at least 2 draws from pwrbll.txt")
    if not filters:    raise ValueError("No usable filter expressions parsed")

    variants = all_variants()
    summary_rows: List[Dict[str, Any]] = []
    flagged_rows: List[Dict[str, Any]] = []
    reverse_rows: List[Dict[str, Any]] = []
    detailed_rows: List[Dict[str, Any]] = []
    keep_rows: List[Dict[str, Any]] = []

    for fid, expr in filters:
        explanation = layman_explanation(expr)
        for v in variants:
            eliminated = tested = 0
            status = "OK"; last_error = ""

            for i in range(1, len(draws)):
                seed_draw, win_draw = draws[i-1], draws[i]
                hot, cold, due = compute_hot_cold_due(draws, i, v, settings.hot_cold_window, settings.due_window)
                ctx = build_ctx(seed_draw, win_draw, v, hot, cold, due)

                keep = True
                if not expr:
                    status = "FLAGGED"; last_error = "empty/normalized-away expression"
                else:
                    try:
                        # Expression True ‚áí eliminate
                        keep = not bool(eval(expr, ALLOWED_GLOBALS, ctx))
                    except Exception as ex:
                        status = "FLAGGED"; last_error = f"{type(ex).__name__}: {ex}"; keep = True

                eliminated += (0 if keep else 1); tested += 1

                if len(detailed_rows) < MAX_DETAILED_ROWS:
                    detailed_rows.append({
                        "filter_id": fid, "variant": v, "index": i,
                        "seed_value": ctx["seed"], "winner_value": ctx["winner"],
                        "seed_draw": seed_draw, "winner_draw": win_draw,
                        "hot_digits": hot, "cold_digits": cold, "due_digits": due,
                        "eliminated": (not keep), "status": status, "error": last_error,
                        "layman_explanation": explanation,
                    })

            stat = f"{eliminated}/{tested}"
            summary_rows.append({
                "filter_id": fid, "variant": v, "eliminated": eliminated,
                "total": tested, "stat": stat, "status": status,
                "layman_explanation": explanation, "expression": expr
            })

            # record flagged once per (filter,variant)
            if status == "FLAGGED":
                flagged_rows.append({
                    "filter_id": fid, "variant": v, "stat": stat,
                    "expression": expr, "error": last_error,
                    "layman_explanation": explanation,
                })

            # reversals (very strong eliminators)
            if tested > 0 and (eliminated/tested) >= settings.reverse_threshold:
                reverse_rows.append({
                    "filter_id": fid, "variant": v, "expression": expr,
                    "eliminated": eliminated, "total": tested, "stat": stat,
                    "threshold": f"‚â•{int(settings.reverse_threshold*100)}%",
                    "layman_explanation": explanation,
                })

            # keepers (safe survivors)
            if tested > 0 and (eliminated/tested) <= settings.keeper_threshold and status == "OK":
                # final-app friendly row
                keep_rows.append({
                    "id": f"{fid}_{v}",
                    "name": f"{fid} ({v})",
                    "enabled": True,
                    "applicable_if": f"(variant_name == '{v}')",
                    "expression": expr,
                    "stats": stat,
                    "explanation": explanation,
                })

    return {
        "draws": draws,
        "summary": pd.DataFrame(summary_rows),
        "flagged": pd.DataFrame(flagged_rows).drop_duplicates(subset=["filter_id","variant"]),
        "reverse": pd.DataFrame(reverse_rows).drop_duplicates(subset=["filter_id","variant"]),
        "keepers": pd.DataFrame(keep_rows),
        "detailed": pd.DataFrame(detailed_rows),
    }

# =======================
# Streamlit UI
# =======================
st.set_page_config(page_title="Filter Runner", layout="wide")
st.title("üé∞ Filter Runner (variant ‚Üí itself)")

with st.sidebar:
    st.header("Settings")
    reverse_input   = st.checkbox("Input is newest ‚Üí oldest (reverse to chronological)", value=True)
    hot_cold_window = st.number_input("Hot/Cold lookback (draws)", 1, 100, 6, 1)
    due_window      = st.number_input("Due lookback (draws)", 1, 20, 2, 1)
    keeper_thr      = st.slider("Keeper threshold (‚â§ eliminated %)", 0.0, 0.5, KEEPER_THRESHOLD_DEFAULT, 0.01)
    reverse_thr     = st.slider("Reversal threshold (‚â• eliminated %)", 0.5, 1.0, REVERSE_THRESHOLD_DEFAULT, 0.01)
    write_detailed  = st.checkbox("Write detailed per-row results", value=False)
    st.caption(f"(Detailed rows capped at {MAX_DETAILED_ROWS:,}.)")

    st.divider()
    st.caption("Upload files or leave blank to use repo files `pwrbll.txt` and `test 4pwrballfilters.txt`.")
    up_draws   = st.file_uploader("Upload pwrbll.txt", type=["txt","csv"])
    up_filters = st.file_uploader("Upload filters (Batch CSV/TXT or id,expression)", type=["txt","csv"])

run = st.button("‚ñ∂Ô∏è Run filters")

# Persist last results to avoid recompute on downloads
if "last_results" not in st.session_state:
    st.session_state.last_results = None
    st.session_state.last_key = None

if run:
    try:
        if up_draws is not None:
            draws_bytes = up_draws.getvalue()
        else:
            draws_bytes = open("pwrbll.txt", "rb").read()

        if up_filters is not None:
            filters_bytes = up_filters.getvalue()
        else:
            filters_bytes = open("test 4pwrballfilters.txt", "rb").read()

        key = (md5_bytes(draws_bytes), md5_bytes(filters_bytes), reverse_input,
               hot_cold_window, due_window, keeper_thr, reverse_thr)

        settings = EvalSettings(
            hot_cold_window=int(hot_cold_window),
            due_window=int(due_window),
            keeper_threshold=float(keeper_thr),
            reverse_threshold=float(reverse_thr),
        )
        results = evaluate_cached(draws_bytes, filters_bytes, reverse_input, settings)
        # Optionally trim detailed
        if not write_detailed:
            results["detailed"] = pd.DataFrame()

        st.session_state.last_results = results
        st.session_state.last_key = key
        st.success(f"Parsed {len(results['draws'])} draws. Computation complete.")
    except Exception as e:
        st.exception(e)

results = st.session_state.last_results
if results is None:
    st.info("Load files and click **Run filters** to begin.")
else:
    summary_df  = results["summary"]
    flagged_df  = results["flagged"]
    reverse_df  = results["reverse"]
    keepers_df  = results["keepers"]
    detailed_df = results["detailed"]

    st.subheader("Results: Summary (per filter √ó variant)")
    st.dataframe(summary_df[["filter_id","variant","eliminated","total","stat","status","layman_explanation"]], use_container_width=True, height=380)
    download_pair(summary_df, "filter_results")

    st.subheader("Keepers (safe filters for final app)")
    st.dataframe(keepers_df, use_container_width=True, height=300)
    download_pair(keepers_df, "keepers")

    st.subheader("Flagged Filters (with error messages)")
    st.dataframe(flagged_df, use_container_width=True, height=260)
    download_pair(flagged_df, "flagged_filters")

    st.subheader("Reversal Candidates (‚â• threshold)")
    st.dataframe(reverse_df, use_container_width=True, height=260)
    download_pair(reverse_df, "reversal_candidates")

    if write_detailed and not detailed_df.empty:
        st.subheader("Detailed (per row tested)")
        st.caption(f"Showing first 50,000 rows (of {len(detailed_df):,}).")
        st.dataframe(detailed_df.head(50_000), use_container_width=True, height=320)
        download_pair(detailed_df, "filter_results_detailed")

    st.info(
        f"Done. Summary rows: {len(summary_df):,} | "
        f"Keepers: {len(keepers_df):,} | "
        f"Flagged: {len(flagged_df):,} | "
        f"Reverse: {len(reverse_df):,}"
    )
